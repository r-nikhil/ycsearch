# YC Search 2025 üöÄ

**Enhanced semantic search for 10,000+ Y Combinator companies (2005-2025)**

This is a modernized and significantly expanded version of the original [ycvibecheck](https://github.com/thesephist/ycvibecheck) by [@thesephist](https://github.com/thesephist). It uses _semantic similarity_ to search Y Combinator's **complete portfolio of 10,459 companies** by descriptions of ideas or verticals rather than keywords or categories.

## ‚ú® What's New in 2025

- **10,459 companies** (up from 4,079) - **+6,380 new companies**
- **Complete coverage**: 2005-2025 across **87 unique batches** 
- **Latest batches**: W25, S25, F24, Sp25 with hundreds of new startups
- **Normalized batch names**: Consistent `W##/S##/F##/Sp##` format
- **Fixed sorting**: Homepage now shows newest companies first
- **Python 3.13** compatibility with updated dependencies

![Screen recording of a search results page on YC Vibe Check](/static/img/screen-recording.gif)

Unlike the simple text search box in YC's [startup directory](https://www.ycombinator.com/companies), semantic search means this search bar doesn't need you to get the keywords exactly right, only close enough to what startups are building, to find them.

## üèÉ‚Äç‚ôÇÔ∏è Quick Start

### 1. **Clone & Setup**
```bash
git clone https://github.com/manassaloi/ycsearch.git
cd ycsearch
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 2. **Generate Embeddings** (Required for search)
```bash
# This will take 15-30 minutes to process 10,459 companies
python server/generate.py
```

### 3. **Run the Server**
```bash
export FLASK_APP=app.py
flask run --port 5001
```

### 4. **Start Searching!**
Visit `http://localhost:5001` and search for:
- `"AI startups"` ‚Üí Latest AI companies across all batches
- `"climate change"` ‚Üí Environmental tech companies  
- `"fintech"` ‚Üí Financial technology startups
- `"W25"` ‚Üí Filter by specific batch

## üìä Dataset Details

- **10,459 YC companies** from 2005-2025 across **87 unique batches**
- **Complete coverage**: Winter, Summer, Fall, and Spring batches
- **Normalized batch names**: W##, S##, F##, Sp## format
- **Latest batches**: W25 (331 cos), S25 (48 cos), F24 (190 cos), Sp25 (143 cos)
- **Embeddings**: 190MB generated with sentence-transformers

YC Search is built with [the Oak language](https://oaklang.org) and [Torus](https://github.com/thesephist/torus). It runs [sentence-transformers](https://www.sbert.net/) behind a [Flask](https://flask.palletsprojects.com/) server on the backend for semantic indexing and search. The dataset is based on [akshaybhalotia/yc_company_scraper](https://github.com/akshaybhalotia/yc_company_scraper).

## How it works

YCVC is not the first semantic search engine I've built ‚Äî that honor goes to [Revery](https://github.com/thesephist/revery), which was a semantic search engine for my personal work and history, like contacts, bookmarks, notes, journals, and tweets. But YCVC performs semantic search quite differently, for a few important reasons we'll get to below.

Revery's semantic search was based on [word embedding vectors](https://en.wikipedia.org/wiki/Word2vec), which maps words or "tokens" in every piece of text to a point in a high-dimensional space such that similar words cluster together. For Revery's semantic index, I simply averaged the word vectors of every word in each document to compute the "embedding" of every document. This is a well-known established method, and I found it worked well enough for me and Revery. It's also relatively resource-efficient, which worked well for the tiny server I had to run that app. (You can read more about how Revery works [in its own README](https://github.com/thesephist/revery#how-it-works).)

But times have changed! Transformer-based language models have learned to speak now and they yearn for more memory and bigger cores and promise great things in return! So YCVC uses one such transformer-based deep learning model, `sentence-transformers/all-mpnet-base-v2`, to compute sentence/paragraph embeddings instead of word vectors.

There's another more practical reason a more sophisticated model is needed for YCVC, which is that unlike long blog posts and journals that are sort of explicit in what they talk about, and generally talk about well-known ideas, YC company pitches and descriptions tend to involve lots of neologisms (NFT, DevOps, "Scale" used ten thousand different ways) and often speak analogically rather than directly. Though I haven't done empirical comparisons of transformers against word vectors in this use cases, I suspect transformer-based models probably perform better at understanding YC company descriptions for these reasons.

Once sentence embeddings are used to compute semantic "neighbors" of an idea or company description, YCVC collects a bunch of metadata to show you about that company. That comes from a few different places:

- The Algolia search API that backs the [YC Startup Directory](https://www.ycombinator.com/companies), which returns basic company information like name, status, descriptions, batch, team size, and location
- Scraping the company's page on YC's directory manually, which returns some more valuable and detailed information like founding year, social media and Crunchbase URLs, and news articles about companies
- Searching the [Hacker News Algolia API](https://hn.algolia.com/) for the company's name, which often turns up relevant stories about companies that aren't necessarily fundraising announcements or other managed PR

The YCVC UI then collects all of that information together and compiles it in a (hopefully) neat little table to surface it to you, the curious searcher!

### Known faults and limitations

My focus on this project was more the interface and building a proof-of-concept for similarity search as a market research tool, and less building the _best possible model_ for this task. So in the process of playing with YCVC during development I've noticed a few mistakes that the current model is prone to making, which I thought I'd document here.

- The model gets easily sidetracked by company names. For example, a search containing the company name "Airbyte" will bring up companies with the subwords "Air" and "Byte" in the name, even though they aren't really in the same industries or markets.
- The model doesn't know about super, super new technical concepts. It knows about NFTs (which I was pleasantly surprised by) and understands that "DevOps" is related to cloud infrastructure. But if next year there are a bunch of YC companies built on some new cutting-edge NLP tech or a new carbon sequestration or space launch process, the model will be completely blind to those new concepts.

## Updating the dataset

**TL;DR** ‚Äî Run `./refresh_yc_data.sh`, preferably with a GPU if you have one.

When new batches of YC are announced and the [YC Startup Directory](https://www.ycombinator.com/companies) is updated with new companies, we need to update the dataset that underlies the YC Vibe Check backend. Updating the dataset is a straightforward process, thanks to an upstream project called [yc_company_scraper](https://github.com/akshaybhalotia/yc_company_scraper). Here are the rough steps:

1. Ensure the `yc_company_scraper` project has an updated `data/yc_essential_data.json` in their repository. If this is updated, everything is pretty simple. If not, we need to figure out how to run the scraper and update the JSON first before moving forward.
2. Download the JSON from that repository to `data/yc.json` in the YC Vibe Check repository.
3. Run `server/generate.py`, which will generate semantic embeddings for every company from its `long_description`, or `one_liner` if the long description is blank.

These steps should produce two updated files, `data/yc.json` and `data/yc-embedded.json`. Only the latter is really needed for the app to run, but I like to keep both in case I want to re-generate the embeddings from scratch. The updated versions of these files should be checked into the repository and deployed.

## Development

Like many of my projects, YC Vibe Check is built and managed with [Oak](https://oaklang.org/). There's a short [Makefile](Makefile) that wraps common `oak` commands:

- `make` runs the Flask web server, and is equivalent to `flask run`
- `make fmt` or `make f` auto-formats any tracked changes in the repository
- `make build` or `make b` builds the client JavaScript bundle from `src/app.js.oak`
- `make watch` or `make w` watches for file changes and runs the `make build` on any change
